#!/usr/bin/env python3
"""
apply_fixes.py - Applies code fixes suggested by Claude AI

This script:
1. Reads the fixes from the Claude AI response
2. Parses each fix to identify file paths and code changes
3. Applies the changes to the appropriate files
4. Validates the changes to ensure they don't break the code

Improved version with incremental fix application and better validation.
"""

import json
import os
import re
import subprocess
import sys
import argparse
import tempfile
from pathlib import Path

# Maximum number of fixes to apply per file to avoid large-scale changes
MAX_FIXES_PER_FILE = 10

# Maximum percentage of file that can be changed (to avoid destructive changes)
# Can be overridden with --force or --max-change-percentage
MAX_CHANGE_PERCENTAGE = 30

def parse_fixes_file(file_path='claude_fixes.json'):
    """Parse the fixes file generated by Claude AI."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            return data.get('fixes', [])
    except FileNotFoundError:
        print(f"Warning: {file_path} file not found")
        return []
    except json.JSONDecodeError:
        print(f"Error: {file_path} is not valid JSON")
        return []
    except Exception as e:
        print(f"Error reading fixes file: {e}")
        return []

def parse_fix_block(fix_text):
    """Parse a single fix block."""
    lines = fix_text.strip().split('\n')
    
    fix_info = {
        'file': None,
        'original': [],
        'fixed': [],
        'explanation': [],
        'current_section': None
    }
    
    for line in lines:
        # File path is specified with "file: path/to/file.rs"
        if line.startswith('file:'):
            fix_info['file'] = line[5:].strip()
        # Start of original code block
        elif line == 'original: |':
            fix_info['current_section'] = 'original'
        # Start of fixed code block
        elif line == 'fixed: |':
            fix_info['current_section'] = 'fixed'
        # Start of explanation block
        elif line == 'explanation: |':
            fix_info['current_section'] = 'explanation'
        # Separator between sections
        elif line == '---':
            fix_info['current_section'] = None
        # Content for the current section
        elif fix_info['current_section']:
            # Remove the leading two spaces if they exist (YAML block scalar indentation)
            if line.startswith('  '):
                line = line[2:]
            fix_info[fix_info['current_section']].append(line)
    
    # Join the content of each section into a single string
    for section in ['original', 'fixed', 'explanation']:
        fix_info[section] = '\n'.join(fix_info[section])
    
    # Clean up
    del fix_info['current_section']
    
    return fix_info

def validate_fix(fix):
    """Validate that a fix has all required components."""
    required_fields = ['file', 'original', 'fixed']
    for field in required_fields:
        if not fix.get(field):
            print(f"Warning: Missing required field '{field}' in fix")
            return False
    
    # Ensure file exists
    if not os.path.isfile(fix['file']):
        print(f"Warning: File {fix['file']} does not exist")
        return False
    
    # Check if original and fixed are identical
    if fix['original'] == fix['fixed']:
        print(f"Warning: Original and fixed code are identical for {fix['file']}")
        return False
    
    return True

def validate_rust_syntax(file_path):
    """Validate Rust file syntax using cargo check."""
    print(f"Validating syntax of {file_path}...")
    
    # Get the crate name from the file path
    try:
        # First use cargo check to validate the entire project
        # This catches most errors and is safer than trying to check individual files
        result = subprocess.run(
            ['cargo', 'check', '--quiet'],
            capture_output=True,
            text=True
        )
        
        if result.returncode != 0:
            print(f"Error: Project validation failed for changes in {file_path}")
            print(result.stderr)
            return False
        
        # For additional safety, we can use rustc to check the file
        # For Rust 2021 edition, uses this approach
        temp_dir = tempfile.mkdtemp()
        temp_file = os.path.join(temp_dir, "temp_check.rs")
        
        # Copy the file content to the temp file
        with open(file_path, 'r', encoding='utf-8') as src:
            file_content = src.read()
        
        # Add the necessary module declarations
        # This is a simplified approach and might not work for all files
        with open(temp_file, 'w', encoding='utf-8') as dst:
            dst.write("// Temporary file for syntax check\n")
            dst.write(file_content)
        
        try:
            # Use rustc in lib mode to check syntax
            result = subprocess.run(
                ['rustc', '--edition=2021', '--crate-type=lib', '-o', os.path.devnull, temp_file],
                capture_output=True,
                text=True
            )
            
            if result.returncode != 0:
                print(f"Warning: Individual file validation failed for {file_path}")
                print(result.stderr)
                # We don't return False here as this might be too strict
                # The cargo check is more reliable for the whole project
        except Exception as e:
            print(f"Warning: Error during file-specific validation: {e}")
        
        # Clean up the temp directory
        try:
            os.remove(temp_file)
            os.rmdir(temp_dir)
        except Exception:
            pass
        
    except Exception as e:
        print(f"Error during validation: {e}")
        return False
    
    return True

def validate_single_file(file_path):
    """Validate a single Rust file for syntax correctness."""
    print(f"Validating {file_path}...")
    
    # Use our improved validate_rust_syntax function
    return validate_rust_syntax(file_path)

def validate_project():
    """Validate the entire project with cargo check."""
    print("Running cargo check to validate all changes...")
    
    result = subprocess.run(['cargo', 'check'], 
                         capture_output=True, 
                         text=True)
    
    if result.returncode != 0:
        print("Error: Changes caused compilation errors:")
        print(result.stderr)
        
        print("Details of errors:")
        for line in result.stderr.split('\n'):
            if "error" in line:
                print(f"  {line}")
        
        return False
    
    print("Project validation successful!")
    return True

def apply_fix_to_file(fix, applied_fixes, dry_run=False, force=False, max_change_percentage=None):
    """Apply a single fix to a file."""
    if not validate_fix(fix):
        return False
    
    file_path = fix['file']
    original = fix['original']
    fixed = fix['fixed']
    
    # Determine the max change percentage to use
    effective_max_change = MAX_CHANGE_PERCENTAGE
    if max_change_percentage is not None:
        effective_max_change = max_change_percentage
    
    # Check if we've already applied the maximum number of fixes to this file
    if file_path in applied_fixes and applied_fixes[file_path] >= MAX_FIXES_PER_FILE:
        print(f"Skipping fix for {file_path}: maximum number of fixes ({MAX_FIXES_PER_FILE}) already applied")
        return False
    
    # Read file content
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
    except Exception as e:
        print(f"Error reading file {file_path}: {e}")
        return False
    
    # Calculate change percentage
    def calculate_change_percentage(old_text, new_text):
        import difflib
        diff = difflib.unified_diff(
            old_text.splitlines(keepends=True),
            new_text.splitlines(keepends=True)
        )
        changes = sum(1 for line in diff if line.startswith('+') or line.startswith('-'))
        total_lines = len(old_text.splitlines())
        if total_lines == 0:
            return 100
        return (changes / total_lines) * 100 / 2  # Divide by 2 as each change counts twice (+ and -)
    
    # Check if the original code exists in the file
    if original not in content:
        # Try normalizing whitespace to fix common matching issues
        normalized_original = re.sub(r'\s+', ' ', original.strip())
        normalized_content = re.sub(r'\s+', ' ', content.strip())
        
        if normalized_original not in normalized_content:
            # Try an even more flexible matching approach with line breaks removed
            no_breaks_original = original.replace('\n', ' ').strip()
            no_breaks_content = content.replace('\n', ' ').strip()
            
            if no_breaks_original not in no_breaks_content:
                print(f"Warning: Original code not found in {file_path}")
                print("Original code snippet (first 100 chars):", original[:100].replace('\n', '\\n'))
                return False
            
            # If we match after removing line breaks, try a more sophisticated approach
            print(f"Using fuzzy matching for {file_path} - line breaks differ")
            pattern = re.escape(no_breaks_original).replace('\\ ', r'\s+')
            pattern = re.compile(pattern, re.DOTALL)
            
            if pattern.search(no_breaks_content):
                # We found a match with the pattern, but we need to be careful with the replacement
                print(f"Warning: Using partial matching for {file_path} - this may not be perfectly accurate")
                # We'll need to manually create a modified file to be safe
                
                # Create a backup
                with open(f"{file_path}.bak", 'w', encoding='utf-8') as f:
                    f.write(content)
                
                # For now, we'll skip this fix as it's too risky to apply automatically
                if not force:
                    print(f"Skipping complex fix for {file_path} - use --force to override")
                    return False
            else:
                return False
        
        # If we match after normalization, use a regex replacement with flexible whitespace
        pattern = re.escape(normalized_original).replace('\\ ', r'\s+')
        try:
            # This is dangerous - we might break the code with regex replacement
            # Let's skip this approach for now as it's too risky
            if not force:
                print(f"Skipping normalized fix for {file_path} - use --force to override")
                return False
                
            updated_content = re.sub(pattern, fixed, normalized_content)
            
            # Change percentage check
            change_percent = calculate_change_percentage(normalized_content, updated_content)
            if change_percent > effective_max_change and not force:
                print(f"Warning: Change too large ({change_percent:.1f}%) for {file_path}, skipping")
                print(f"Use --force to apply changes regardless of size")
                return False
        except Exception as e:
            print(f"Error applying regex replacement: {e}")
            return False
    else:
        # Simple replacement
        updated_content = content.replace(original, fixed)
        
        # Change percentage check
        change_percent = calculate_change_percentage(content, updated_content)
        if change_percent > effective_max_change and not force:
            print(f"Warning: Change too large ({change_percent:.1f}%) for {file_path}, skipping")
            print(f"Use --force to apply changes regardless of size")
            return False
    
    # If the content didn't change, no need to continue
    if content == updated_content:
        print(f"No changes needed for {file_path}")
        return False
    
    if dry_run:
        print(f"Would update {file_path} (change: {change_percent:.1f}%)")
        return True
    
    # Create a backup of the original file
    backup_path = f"{file_path}.bak"
    with open(backup_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    # Apply the changes
    try:
        # Write the updated content
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(updated_content)
        
        # Update applied fixes count
        if file_path not in applied_fixes:
            applied_fixes[file_path] = 1
        else:
            applied_fixes[file_path] += 1
        
        print(f"Updated {file_path} (applied fix {applied_fixes[file_path]}/{MAX_FIXES_PER_FILE})")
        print(f"Backup saved to {backup_path}")
        return True
    except Exception as e:
        print(f"Error writing to file {file_path}: {e}")
        return False

def revert_file(file_path):
    """Revert a file to its backup version."""
    backup_path = f"{file_path}.bak"
    if os.path.exists(backup_path):
        try:
            os.rename(backup_path, file_path)
            print(f"Reverted changes to {file_path}")
            return True
        except Exception as e:
            print(f"Error reverting {file_path}: {e}")
            print(f"Manual restore needed from {backup_path}")
            return False
    else:
        print(f"No backup found for {file_path}")
        return False

def main():
    # Parse command line arguments
    parser = argparse.ArgumentParser(description='Apply fixes from Claude AI')
    parser.add_argument('--force', action='store_true', 
                        help='Force applying fixes regardless of change size')
    parser.add_argument('--max-change', type=float, dest='max_change_percentage', default=50.0,
                        help=f'Maximum percentage of file that can be changed (default: 50%%)')
    parser.add_argument('--fixes-file', type=str, default='claude_fixes.json',
                        help='Path to the JSON file containing fixes (default: claude_fixes.json)')
    parser.add_argument('--no-interactive', action='store_true',
                        help='Run in non-interactive mode (no prompts)')
    parser.add_argument('--no-validation', action='store_true',
                        help='Skip validation of changes')
    parser.add_argument('--incremental', action='store_true',
                        help='Apply and validate fixes incrementally (one at a time)')
    args = parser.parse_args()
    
    # Parse the fixes
    raw_fixes = parse_fixes_file(args.fixes_file)
    
    if not raw_fixes:
        print("No fixes to apply")
        # Write to changes_count.txt for GitHub Actions
        with open('changes_count.txt', 'w') as f:
            f.write("0")
        
        # Use the newer GitHub Actions output method
        if 'GITHUB_OUTPUT' in os.environ:
            with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                f.write(f"has_changes=0\n")
                f.write(f"changes_valid=false\n")
        sys.exit(0)
    
    print(f"Found {len(raw_fixes)} potential fixes to apply")
    
    # Parse each fix block
    fixes = []
    for fix_text in raw_fixes:
        try:
            fix = parse_fix_block(fix_text)
            fixes.append(fix)
        except Exception as e:
            print(f"Error parsing fix: {e}")
    
    print(f"Successfully parsed {len(fixes)} fixes")
    
    # Group fixes by file
    fixes_by_file = {}
    for fix in fixes:
        if not fix.get('file'):
            continue
        file_path = fix['file']
        if file_path not in fixes_by_file:
            fixes_by_file[file_path] = []
        fixes_by_file[file_path].append(fix)
    
    # Apply the fixes
    applied_fixes = {}  # Track how many fixes we've applied to each file
    changed_files = set()  # Track which files we've changed
    failed_fixes = []  # Track fixes that failed to apply or validate
    
    # First do a dry run to count how many files would change
    print("Performing dry run...")
    dry_run_changes = set()
    for fix in fixes:
        if apply_fix_to_file(fix, {}, dry_run=True, force=args.force, 
                           max_change_percentage=args.max_change_percentage):
            dry_run_changes.add(fix['file'])
    
    print(f"Dry run complete. {len(dry_run_changes)} files would be changed.")
    
    # Ask for confirmation in interactive mode
    if not args.no_interactive and dry_run_changes:
        try:
            confirmation = input(f"Apply changes to {len(dry_run_changes)} files? (y/n): ").lower()
            if confirmation != 'y':
                print("Operation cancelled by user")
                # Write to changes_count.txt for GitHub Actions
                with open('changes_count.txt', 'w') as f:
                    f.write("0")
                
                # Use the newer GitHub Actions output method
                if 'GITHUB_OUTPUT' in os.environ:
                    with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                        f.write(f"has_changes=0\n")
                        f.write(f"changes_valid=false\n")
                sys.exit(0)
        except EOFError:
            print("Non-interactive environment detected, proceeding without confirmation")
    
    # Incremental mode: apply and validate one fix at a time
    if args.incremental:
        print("Using incremental mode: applying and validating fixes one at a time")
        
        for fix in fixes:
            file_path = fix['file']
            
            # Apply this fix
            if apply_fix_to_file(fix, applied_fixes, force=args.force, 
                               max_change_percentage=args.max_change_percentage):
                changed_files.add(file_path)
                
                # Validate this specific file
                if not args.no_validation:
                    if not validate_single_file(file_path):
                        print(f"Validation failed for {file_path}, reverting changes")
                        revert_file(file_path)
                        changed_files.remove(file_path)
                        failed_fixes.append(fix)
                        continue
                
                # Validate the whole project with cargo check
                # We do this for each file because some issues only appear when the whole project is built
                if not args.no_validation:
                    if not validate_project():
                        print(f"Project validation failed after fixing {file_path}, reverting changes")
                        revert_file(file_path)
                        changed_files.remove(file_path)
                        failed_fixes.append(fix)
    else:
        # Batch mode: apply all fixes then validate
        print("Using batch mode: applying all fixes before validation")
        
        # Apply all fixes
        for fix in fixes:
            file_path = fix['file']
            if apply_fix_to_file(fix, applied_fixes, force=args.force,
                               max_change_percentage=args.max_change_percentage):
                changed_files.add(file_path)
        
        # Validate all changed files
        if not args.no_validation and changed_files:
            # First validate each file's syntax
            invalid_files = []
            for file_path in changed_files:
                if not validate_single_file(file_path):
                    invalid_files.append(file_path)
            
            # Then validate the entire project
            project_valid = validate_project()
            
            # If any validation failed, revert all changes
            if invalid_files or not project_valid:
                print("Validation failed, reverting all changes")
                for file_path in changed_files:
                    revert_file(file_path)
                changed_files = set()
    
    # Summary
    print("\n=== Summary ===")
    print(f"Total fixes found: {len(fixes)}")
    print(f"Files changed: {len(changed_files)}")
    print(f"Failed fixes: {len(failed_fixes)}")
    
    # Write output for GitHub Actions
    with open('changes_count.txt', 'w') as f:
        f.write(str(len(changed_files)))
    
    # Use the newer GitHub Actions output method
    if 'GITHUB_OUTPUT' in os.environ:
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f"has_changes={1 if changed_files else 0}\n")
            f.write(f"changes_valid={len(failed_fixes) == 0}\n")
    
    # If we made changes, exit with code 1 to indicate changes were made
    # This can be used in CI to trigger a commit
    if changed_files:
        sys.exit(1)
    else:
        sys.exit(0)

if __name__ == "__main__":
    main()
